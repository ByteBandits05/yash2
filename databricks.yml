# ============================================================
# FILE: databricks.yml
# PURPOSE: Databricks Asset Bundle Configuration (DAB) for CI/CD Automation
# DESCRIPTION: Standards-compliant, parameterized template for multi-environment deployment and reusable smoke-test workflow.
# ============================================================

bundle:
  # Name of the asset bundle (placeholder for parameterization)
  name: my_bundle

# ------------------------------------------------------------
# Deployment Targets (dev, qa, prod) with parameterized values
# ------------------------------------------------------------
targets:
  dev:
    # Default deployment target
    default: true
    workspace:
      host: ${DATABRICKS_HOST_DEV}         # Dev workspace host (parameterized)
      root_path: ${ROOT_PATH_DEV}          # Dev root path (parameterized)
      file_path: ${FILE_PATH_DEV}          # Dev file path (parameterized)
  qa:
    workspace:
      host: ${DATABRICKS_HOST_QA}          # QA workspace host (parameterized)
      root_path: ${ROOT_PATH_QA}           # QA root path (parameterized)
      file_path: ${FILE_PATH_QA}           # QA file path (parameterized)
  prod:
    workspace:
      host: ${DATABRICKS_HOST_PROD}        # Prod workspace host (parameterized)
      root_path: ${ROOT_PATH_PROD}         # Prod root path (parameterized)
      file_path: ${FILE_PATH_PROD}         # Prod file path (parameterized)

# ------------------------------------------------------------
# Resources: Jobs / Workflows Section (parameterized)
# ------------------------------------------------------------
resources:
  jobs:
    smoke-test:
      name: smoke-test
      # Smoke test task: runs a notebook using a parameterized job cluster
      tasks:
        - task_key: smoke_test_task
          notebook_task:
            notebook_path: /Workspace/smoketest/smoke_test.py  # Path to smoke test notebook/script
            source: WORKSPACE
          job_cluster_key: smoke_job_cluster
      job_clusters:
        - job_cluster_key: smoke_job_cluster
          new_cluster:
            cluster_name: ""
            spark_version: ${SMOKE_SPARK_VERSION}
            node_type_id: ${SMOKE_NODE_TYPE}
            num_workers: ${SMOKE_NUM_WORKERS}
            autotermination_minutes: ${SMOKE_AUTOTERM_MINUTES}
