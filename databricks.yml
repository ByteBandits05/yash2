# -----------------------------------------------------------------------------
# File: databricks.yml
# Purpose: Databricks Asset Bundle configuration for CI/CD with multi-target support
# Includes workspace and workflow definitions. All values are parameterized.
# -----------------------------------------------------------------------------

bundle:
  # Bundle name (change as appropriate)
  name: my_bundle

# ----------------------------------------------------------------------
# Targets for different environments (dev, qa, prod)
# Each target uses environment variables for host, root_path, and file_path
# ----------------------------------------------------------------------
targets:
  dev:
    default: true  # Mark 'dev' as the default deployment target
    workspace:
      host: ${DATABRICKS_HOST_DEV}      # Databricks workspace host for dev
      root_path: ${ROOT_PATH_DEV}       # Root path in dev workspace
      file_path: ${FILE_PATH_DEV}       # File path in dev workspace

  qa:
    workspace:
      host: ${DATABRICKS_HOST_QA}
      root_path: ${ROOT_PATH_QA}
      file_path: ${FILE_PATH_QA}

  prod:
    workspace:
      host: ${DATABRICKS_HOST_PROD}
      root_path: ${ROOT_PATH_PROD}
      file_path: ${FILE_PATH_PROD}

# ----------------------------------------------------------------------
# Workflows section for reusable job definitions
# ----------------------------------------------------------------------
workflows:
  smoke-test:
    name: smoke-test
    tasks:
      - task_key: smoke_test
        description: "Run smoke test notebook to validate deployment"
        existing_cluster_id: ${SMOKE_TEST_CLUSTER_ID}
        notebook_task:
          notebook_path: /Workspace/smoketest/smoke_test.py
    # Cluster and resource config as placeholders
    cluster:
      spark_version: ${SMOKE_TEST_SPARK_VERSION}
      node_type_id: ${SMOKE_TEST_NODE_TYPE}
      num_workers: ${SMOKE_TEST_NUM_WORKERS}
     
