# -----------------------------------------------------------------------------
# File: .github/workflows/cicd_pipeline.yml
# Purpose: GitHub Actions Workflow for Databricks CI/CD Pipeline with Asset Bundles & OIDC Auth
# Triggers on workflow_dispatch and pushes to main. Fully parameterized for enterprise use.
# -----------------------------------------------------------------------------

name: Databricks CI/CD Pipeline

on:
  workflow_dispatch:            # Manual trigger
  push:
    branches:
      - main                   # Trigger on push to main branch

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      # Map GitHub secrets to environment variables
      AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
      AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
      AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
      DATABRICKS_HOST_DEV: ${{ secrets.DATABRICKS_HOST_DEV }}
      ROOT_PATH_DEV: ${{ secrets.ROOT_PATH_DEV }}
      FILE_PATH_DEV: ${{ secrets.FILE_PATH_DEV }}
      # Add additional environment variables as needed

    steps:
      # -------------------------------------------------------------
      # Step 1: Checkout repository
      # -------------------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v4

      # -------------------------------------------------------------
      # Step 2: Setup Databricks CLI v2
      # -------------------------------------------------------------
      - name: Setup Databricks CLI v2
        uses: databricks/setup-cli@main

      # -------------------------------------------------------------
      # Step 3: Print debug envs (for troubleshooting)
      # -------------------------------------------------------------
      - name: Print debug envs
        run: |
          echo "DATABRICKS_HOST_DEV=$DATABRICKS_HOST_DEV"
          echo "AZURE_CLIENT_ID=$AZURE_CLIENT_ID"
          echo "AZURE_TENANT_ID=$AZURE_TENANT_ID"
          # Do not echo secrets in real prod!

    

      # -------------------------------------------------------------
      # Step 5: Validate Databricks Asset Bundle
      # -------------------------------------------------------------
      - name: Validate bundle configuration
        run: databricks bundle validate

      # -------------------------------------------------------------
      # Step 6: Deploy Asset Bundle to dev environment
      # -------------------------------------------------------------
      - name: Deploy bundle to dev (force lock)
        run: databricks bundle deploy --target dev --force-lock

      # -------------------------------------------------------------
      # Step 7: Run smoke test notebook via Databricks CLI
      # -------------------------------------------------------------
      - name: Run smoke test
        run: |
          if [ ! -f smoketest/smoke_test.py ]; then
            echo "ERROR: smoketest/smoke_test.py not found."
            exit 1
          fi
          databricks workflows run --job-name smoke-test --json
